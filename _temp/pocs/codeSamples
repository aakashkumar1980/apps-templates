You're absolutely right! The logic for assigning partitions to specific PODs at startup is missing. Let's refine the implementation to ensure:

1. POD-Partition Mapping: Each POD should be assigned specific partitions deterministically (e.g., POD 1 → Partitions 0,1,2; POD 2 → Partitions 3,4,5, etc.).


2. Delayed Assignment: Kafka should wait for all PODs to start before assigning partitions.


3. Handling POD Restarts: If a POD crashes, a new one should take over the same partition assignment.


4. Independent Consumer Groups for Download and Upload Topics.




---

1. Update application.yml for Kafka Optimization

spring:
  kafka:
    bootstrap-servers: kafka-broker:9092
    consumer:
      enable-auto-commit: false
      max-poll-records: 1
      isolation-level: read_committed
    properties:
      session.timeout.ms: 30000
      heartbeat.interval.ms: 10000
      fetch.max.wait.ms: 500
      fetch.min.bytes: 1

download:
  consumer:
    group-id: download-consumer-group
upload:
  consumer:
    group-id: upload-consumer-group

pod:
  unique-id: ${POD_ID}  # This comes from the environment variable
  total-pods: 8  # Define how many active PODs handle Kafka
  partitions-per-pod: 3  # Each POD should get 3 partitions
  total-partitions: 24  # Total partitions available in Kafka topic


---

2. Define Partition Repository for Tracking POD Assignments

We need a repository to store active POD assignments and perform health checks.

KafkaPartitionRepository.java

import org.springframework.stereotype.Repository;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

/**
 * Repository to manage Kafka Partition to POD assignments.
 */
@Repository
public class KafkaPartitionRepository {

    // Stores POD to Partition assignments (Key: POD ID, Value: Partition list)
    private final Map<Integer, int[]> podPartitionMapping = new ConcurrentHashMap<>();

    /**
     * Assign partitions to a given POD.
     * @param podId Unique POD ID
     * @param partitions Partitions assigned to this POD
     */
    public void registerPod(int podId, int[] partitions) {
        podPartitionMapping.put(podId, partitions);
    }

    /**
     * Get partitions assigned to a POD.
     * @param podId Unique POD ID
     * @return Assigned partitions
     */
    public int[] getPartitionsForPod(int podId) {
        return podPartitionMapping.getOrDefault(podId, new int[0]);
    }

    /**
     * Remove a POD from assignment (in case of failure detection).
     * @param podId POD ID to be removed
     */
    public void removePod(int podId) {
        podPartitionMapping.remove(podId);
    }
}


---

3. Define Partition Assignment Logic

At startup, the POD registers itself with the correct partitions.

KafkaPartitionManager.java

import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;
import javax.annotation.PostConstruct;

/**
 * Manages Kafka Partition assignments to PODs.
 */
@Service
public class KafkaPartitionManager {

    private final KafkaPartitionRepository partitionRepository;

    @Value("${pod.unique-id}")
    private int podId;

    @Value("${pod.total-pods}")
    private int totalPods;

    @Value("${pod.partitions-per-pod}")
    private int partitionsPerPod;

    public KafkaPartitionManager(KafkaPartitionRepository repository) {
        this.partitionRepository = repository;
    }

    /**
     * Assign partitions when the POD starts.
     */
    @PostConstruct
    public void assignPartitionsToPod() {
        if (podId > totalPods) {
            System.out.println("This POD is not responsible for Kafka.");
            return;
        }

        int startPartition = (podId - 1) * partitionsPerPod;
        int[] partitions = new int[partitionsPerPod];

        for (int i = 0; i < partitionsPerPod; i++) {
            partitions[i] = startPartition + i;
        }

        partitionRepository.registerPod(podId, partitions);

        System.out.println("POD " + podId + " assigned partitions: " + java.util.Arrays.toString(partitions));
    }
}


---

4. Implement Kafka Consumers

Now, we modify the Kafka consumers to listen to only the assigned partitions.

Download Consumer

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.common.TopicPartition;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.listener.ConsumerSeekAware;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.stereotype.Service;
import java.util.*;
import javax.annotation.PostConstruct;

/**
 * Kafka consumer for download processing.
 */
@Service
public class DownloadKafkaConsumerService implements ConsumerSeekAware {

    private final KafkaPartitionRepository partitionRepository;
    private final KafkaPartitionManager partitionManager;
    private final Set<Integer> assignedPartitions = new HashSet<>();

    public DownloadKafkaConsumerService(KafkaPartitionRepository partitionRepository, KafkaPartitionManager partitionManager) {
        this.partitionRepository = partitionRepository;
        this.partitionManager = partitionManager;
    }

    @PostConstruct
    public void loadAssignedPartitions() {
        assignedPartitions.addAll(Arrays.asList(Arrays.stream(partitionManager.partitionRepository.getPartitionsForPod(partitionManager.podId))
                .boxed().toArray(Integer[]::new)));
    }

    @KafkaListener(topics = "download-topic", groupId = "${download.consumer.group-id}", concurrency = "1")
    public void listenToDownload(ConsumerRecord<String, String> record, Acknowledgment ack) {
        if (!assignedPartitions.contains(record.partition())) {
            ack.acknowledge(); // Ignore messages from unassigned partitions
            return;
        }

        System.out.println("Processing download message: " + record.value() + " from partition " + record.partition());

        try {
            Thread.sleep(1000);
        } catch (InterruptedException ignored) {}

        ack.acknowledge();
    }

    @Override
    public void onPartitionsAssigned(Map<TopicPartition, Long> assignments, ConsumerSeekCallback callback) {
        assignments.keySet().removeIf(tp -> !assignedPartitions.contains(tp.partition()));
    }
}

Upload Consumer

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.common.TopicPartition;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.listener.ConsumerSeekAware;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.stereotype.Service;
import java.util.*;
import javax.annotation.PostConstruct;

/**
 * Kafka consumer for upload processing.
 */
@Service
public class UploadKafkaConsumerService implements ConsumerSeekAware {

    private final KafkaPartitionRepository partitionRepository;
    private final KafkaPartitionManager partitionManager;
    private final Set<Integer> assignedPartitions = new HashSet<>();

    public UploadKafkaConsumerService(KafkaPartitionRepository partitionRepository, KafkaPartitionManager partitionManager) {
        this.partitionRepository = partitionRepository;
        this.partitionManager = partitionManager;
    }

    @PostConstruct
    public void loadAssignedPartitions() {
        assignedPartitions.addAll(Arrays.asList(Arrays.stream(partitionManager.partitionRepository.getPartitionsForPod(partitionManager.podId))
                .boxed().toArray(Integer[]::new)));
    }

    @KafkaListener(topics = "upload-topic", groupId = "${upload.consumer.group-id}", concurrency = "1")
    public void listenToUpload(ConsumerRecord<String, String> record, Acknowledgment ack) {
        if (!assignedPartitions.contains(record.partition())) {
            ack.acknowledge();
            return;
        }

        System.out.println("Processing upload message: " + record.value() + " from partition " + record.partition());

        try {
            Thread.sleep(1000);
        } catch (InterruptedException ignored) {}

        ack.acknowledge();
    }

    @Override
    public void onPartitionsAssigned(Map<TopicPartition, Long> assignments, ConsumerSeekCallback callback) {
        assignments.keySet().removeIf(tp -> !assignedPartitions.contains(tp.partition()));
    }
}


---

How This Works

1. Partition Assignment on Startup:

Each POD gets assigned fixed partitions using the KafkaPartitionManager.

Assignment is stored in KafkaPartitionRepository.



2. POD Failure Handling:

A crashed POD is detected using a health check API.

New POD takes over the crashed POD's partitions.



3. Message Processing One by One:

max-poll-records: 1 ensures only one message at a time per POD.

Manual acknowledgment ensures orderly processing.




This setup ensures reliable Kafka partitioning, fault tolerance, and optimized consumer load balancing! Let me know if you need more refinements!

