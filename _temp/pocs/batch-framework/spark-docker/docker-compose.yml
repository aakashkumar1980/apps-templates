version: '3'
services:
  ######################
  ### HADOOP CLUSTER ###
  ######################
  namenode:
    image: apache/hadoop:3
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./conf/config.properties
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    volumes:
      - ./data/namenode_data:/hadoop/dfs/name
      - ./conf/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./conf/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml      
    networks:
      - spark_hadoop_network

  datanode1:
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    env_file:
      - ./conf/config.properties
    depends_on:
      - namenode
    volumes:
      - ./data/datanode_data1:/hadoop/dfs/data
      - ./conf/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./conf/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml  
    networks:
      - spark_hadoop_network

  datanode2:
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    env_file:
      - ./conf/config.properties
    depends_on:
      - namenode
    volumes:
      - ./data/datanode_data2:/hadoop/dfs/data
      - ./conf/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./conf/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml 
    networks:
      - spark_hadoop_network

  resourcemanager:
    image: apache/hadoop:3
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
      - 8088:8088
    env_file:
      - ./conf/config.properties
    volumes:
      - ./conf/yarn-site.xml:/opt/hadoop/etc/hadoop/yarn-site.xml
      - ./conf/mapred-site.xml:/opt/hadoop/etc/hadoop/mapred-site.xml
    networks:
      - spark_hadoop_network

  nodemanager:
    image: apache/hadoop:3
    command: ["yarn", "nodemanager"]
    env_file:
      - ./conf/config.properties
    volumes:
      - ./conf/yarn-site.xml:/opt/hadoop/etc/hadoop/yarn-site.xml
      - ./conf/mapred-site.xml:/opt/hadoop/etc/hadoop/mapred-site.xml      
    depends_on:
      - resourcemanager
    networks:
      - spark_hadoop_network


  #####################
  ### SPARK CLUSTER ###
  #####################
  spark-master:
    image: custom-spark:v1
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - spark_master:/bitnami/spark
    networks:
      - spark_hadoop_network  

  spark-worker:
    image: custom-spark:v1
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=${calculatedWorkerMemory}g
      - SPARK_WORKER_CORES=${numvCPU}
    deploy:
      replicas: ${numWorkers}
    volumes:
      - spark_workers:/bitnami/spark
    networks:
      - spark_hadoop_network  


  ########################
  ### JUPYTER NOTEBOOK ###
  ########################
  # jupyter:
  #   image: jupyter/pyspark-notebook:spark-3.3.2
  #   # spark-3.4.0
  #   ports:
  #     - "8888:8888"
  #   environment:
  #     - JUPYTER_ENABLE_LAB=yes
  #   command: start-notebook.sh --NotebookApp.token='' --NotebookApp.password=''  
  #   volumes:
  #     - ./data/notebooks:/home/jovyan/work
  #   depends_on:
  #     - spark-master
  #   networks:
  #     - spark_hadoop_network


volumes:
  namenode_data:
  datanode_data1:
  datanode_data2:
  spark_master:
  spark_workers:
  #notebooks:

networks:
  spark_hadoop_network:
    driver: bridge

    